{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intact Medical Specialty Classification Model using NLP\n",
    "\n",
    "### By: Daniyal, Hibah, Abhishek and Adam\n",
    "\n",
    "Guys, I think it's better if we use the Jupyter notebook(the .ipynb file) to do our data stuff.\n",
    "\n",
    "This is Jupyter Notebooks.\n",
    "Basically, it's divided into these boxes called cells. There are two types of cells: Markdown and Python.\n",
    "We write comments on the \"Markdown\" cell and write code on the \"Python\" cell. This is useful because we cvan run each of the Python cells individually for the pandas dataframe.\n",
    "\n",
    "I wrote down a tentative checklist (**divided into steps**) for this whole project. Feel free to edit as much as you want."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries and read in the data\n",
    "\n",
    "We'll add more libraries, as we move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"new_train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"new_test.csv\", index_col=0)\n",
    "\n",
    "print(\"Train size: \", len(train_df))\n",
    "print(\"Test size: \", len(test_df))\n",
    "\n",
    "train_df.head(n=20) # prints the first 20 rows of the dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Pre-process our data\n",
    "\n",
    "I think this is the most important step here, the ML model is only as good as its dataset, so we gotta make sure it's squeaky clean lol.\n",
    "\n",
    "Some filters we can apply on our data:\n",
    "- Tokenize (divide words individually)\n",
    "- Remove stop-words (remove \"the, and, to, or, ...\")\n",
    "- Lemmatize (convert similar words into its base root; eating, eats, ate => eat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blah blah blah more code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train our models here\n",
    "\n",
    "Daniyal found a really nice article. So basically, I think we should create 4 models (I guess using various different libraries), namely \"Decision Tree, Random Forest, Naive Bayes, and K-Nearest Neighbours\" and we'll see which models the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more python code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate, modify and adjust the model, i guess???\n",
    "\n",
    "Ok idk, I guess it's just rinse and repeat?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a284d3288711230a24215974ec0abd0aa85c769b4796ecd862439a60db1f8ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
